{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code snippet to check if your local machine has GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU if available\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "    print(\"CUDA not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   ID              SIZE      MODIFIED     \n",
      "llama3.2-vision:11b    085a1fdae525    7.9 GB    8 hours ago     \n",
      "deepseek-r1:14b        ea35dfe18182    9.0 GB    17 hours ago    \n",
      "phi4:latest            ac896e5b8b34    9.1 GB    17 hours ago    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def execute_command(command: str):\n",
    "    \"\"\"\n",
    "    Executes a command in the command prompt (Windows) or shell (Linux/macOS) and returns the output.\n",
    "\n",
    "    :param command: The command to execute as a string.\n",
    "    :return: The command output as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, text=True, capture_output=True)\n",
    "        return result.stdout if result.stdout else result.stderr\n",
    "    except Exception as e:\n",
    "        return str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìü Local Machine Name: SriluRoop\n",
      "üåê Local IP Address: 100.64.52.177\n",
      "üöÄ Using model: llama3.2-vision:11b\n",
      "üìù OCR Result:\n",
      "Error processing image: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import socket\n",
    "from ollama_ocr import OCRProcessor\n",
    "\n",
    "def get_local_machine_details():\n",
    "    \"\"\"\n",
    "    Retrieve details about the local machine.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hostname = socket.gethostname()\n",
    "        ip_address = socket.gethostbyname(hostname)\n",
    "        print(f\"üìü Local Machine Name: {hostname}\")\n",
    "        print(f\"üåê Local IP Address: {ip_address}\")\n",
    "        return hostname, ip_address\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error retrieving local machine details: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def process_image_with_ollama(image_path, model_name=\"llama3.2-vision:11b\"):\n",
    "    \"\"\"\n",
    "    Process an image using the OCRProcessor after verifying the Ollama server.\n",
    "    \"\"\"\n",
    "    # Retrieve local machine details\n",
    "    get_local_machine_details()\n",
    "\n",
    "    try:\n",
    "        # Initialize OCRProcessor\n",
    "        print(f\"üöÄ Using model: {model_name}\")\n",
    "        ocr = OCRProcessor(model_name=model_name)\n",
    "\n",
    "        # Process the image\n",
    "        result = ocr.process_image(\n",
    "            image_path=image_path,\n",
    "            format_type=\"key_value\",  # Output format: markdown\n",
    "            preprocess=True          # Preprocess the image\n",
    "        )\n",
    "        print(\"üìù OCR Result:\")\n",
    "        print(result)\n",
    "        return  result\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"‚ùå Could not connect to the Ollama server. Please ensure it is running and accessible.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred during image processing: {e}\")\n",
    "\n",
    "# Run the enhanced code\n",
    "result = process_image_with_ollama(\"cstcbill.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed data saved to costco_bill.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Raw OCR result\n",
    "ocr_result = result\n",
    "\n",
    "# Parsing the OCR result\n",
    "def parse_ocr_result(ocr_text):\n",
    "    # Split lines and initialize data structure\n",
    "    lines = ocr_text.strip().split(\"\\n\")\n",
    "    data = {\n",
    "        \"store\": \"\",\n",
    "        \"location\": \"\",\n",
    "        \"subtotal_tax\": \"\",\n",
    "        \"approved_purchase_amount\": \"\",\n",
    "        \"visa\": \"\",\n",
    "        \"chip_read\": \"\",\n",
    "        \"member_id\": \"\",\n",
    "        \"items\": []\n",
    "    }\n",
    "\n",
    "    # Loop through lines to parse data\n",
    "    for line in lines:\n",
    "        if \"**COSTCO WHOLESALE**\" in line:\n",
    "            parts = line.split(\": \")\n",
    "            data[\"store\"] = \"COSTCO WHOLESALE\"\n",
    "            data[\"location\"] = parts[1].strip()\n",
    "        elif \"**SUBTOTAL TAX**\" in line:\n",
    "            data[\"subtotal_tax\"] = line.split(\": \")[1].strip()\n",
    "        elif \"**APPROVED PURCHASE AMOUNT**\" in line:\n",
    "            data[\"approved_purchase_amount\"] = line.split(\": \")[1].strip()\n",
    "        elif \"**VISA**\" in line:\n",
    "            data[\"visa\"] = line.split(\": \")[1].strip()\n",
    "        elif \"**CHIP READ**\" in line:\n",
    "            data[\"chip_read\"] = line.split(\": \")[1].strip()\n",
    "        elif \"**MEMBER ID**\" in line:\n",
    "            data[\"member_id\"] = line.split(\": \")[1].strip()\n",
    "        elif \"+ \" in line:\n",
    "            # Parse items\n",
    "            item_parts = line.split(\": \")\n",
    "            item_name = item_parts[0].strip(\"+ \").strip()\n",
    "            item_price = item_parts[1].strip()\n",
    "            data[\"items\"].append({\"name\": item_name, \"price\": item_price})\n",
    "\n",
    "    return data\n",
    "\n",
    "# Parse the OCR result\n",
    "parsed_data = parse_ocr_result(ocr_result)\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"costco_bill.json\", \"w\") as json_file:\n",
    "    json.dump(parsed_data, json_file, indent=4)\n",
    "\n",
    "print(\"Parsed data saved to costco_bill.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnagaprofile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
